# app.py â€” Psychiatric Dropout Risk
# (multi-diagnoses + literature-inspired policy overlay + global calibration + smooth blend
#  + border bands + SHAP + Detailed Actions(+Why) + SOP + Batch with drivers & actions top3)
import os
import re
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import shap
import matplotlib.pyplot as plt
from io import BytesIO

try:
    from docx import Document
    HAS_DOCX = True
except Exception:
    HAS_DOCX = False

st.set_page_config(page_title="Psychiatric Dropout Risk", layout="wide")
st.title("ğŸ§  Psychiatric Dropout Risk Predictor")

# ==== Sigmoid / logit helpers ====
def _sigmoid(x): return 1.0 / (1.0 + np.exp(-x))
def _logit(p, eps=1e-6):
    p = float(np.clip(p, eps, 1 - eps)); return np.log(p / (1 - p))
def _logit_vec(p, eps=1e-6):
    p = np.clip(p, eps, 1 - eps); return np.log(p / (1 - p))

# === Global calibration + smoothing ===
CAL_LOGIT_SHIFT = float(os.getenv("RISK_CAL_SHIFT", "0.40"))   # å…¨åŸŸæ ¡æ­£ï¼ˆ+ å¾€ä¸Šã€- å¾€ä¸‹ï¼‰
SOFT_UPLIFT = {"floor": 0.65, "add": 0.20, "cap": 0.95}        # è‡ªå‚· upliftï¼ˆä¸‹é™/åŠ æˆ/ä¸Šé™ï¼‰
BLEND_W = 0.50                                                 # Final = (1-BLEND)*Model + BLEND*Overlay
BORDER_BAND = 7                                                # é‚Šå¸¶å¯¬åº¦ï¼ˆscore 0â€“100ï¼‰

# ====== Unified options ======
DIAG_LIST = [
    "Schizophrenia","Bipolar","Depression","Personality Disorder",
    "Substance Use Disorder","Dementia","Anxiety","PTSD","OCD","ADHD","Other/Unknown"
]
BIN_YESNO = ["Yes","No"]
GENDER_LIST = ["Male","Female"]

# ====== Feature templateï¼ˆç„¡ç¤¾å·¥è®Šæ•¸ï¼‰======
TEMPLATE_COLUMNS = [
    "age","length_of_stay","num_previous_admissions",
    "medication_compliance_score","family_support_score","post_discharge_followups",
    "gender_Male","gender_Female",
] + [f"diagnosis_{d}" for d in DIAG_LIST] + [
    "has_recent_self_harm_Yes","has_recent_self_harm_No",
    "self_harm_during_admission_Yes","self_harm_during_admission_No",
]

# ====== Literature-inspired policy overlay weights (log-odds) ======
POLICY = {
    # å¼·å½±éŸ¿
    "per_prev_admission": 0.18,         # æ¯å¤š 1 æ¬¡æ—¢å¾€ä½é™¢ â†‘ 0.18ï¼ˆä¸Šé™ 5 æ¬¡ï¼‰
    "per_point_low_compliance": 0.24,   # (5 - compliance) æ¯ 1 åˆ† â†‘ 0.24
    "per_point_low_support": 0.20,      # (5 - family support) æ¯ 1 åˆ† â†‘ 0.20
    # è¼•/ä¸­ç­‰å½±éŸ¿
    "per_followup": -0.15,              # æ¯ 1 æ¬¡å‡ºé™¢è¿½è¹¤ â†“ 0.15
    "los_short": 0.45,                  # <3d
    "los_mid": 0.00,                    # 3â€“14d
    "los_mid_high": 0.15,               # 15â€“21d
    "los_long": 0.35,                   # >21d
    # å¹´é½¡æ¥µç«¯
    "age_young": 0.10,                  # <21
    "age_old": 0.10,                    # â‰¥75
    # è¨ºæ–·ï¼ˆå¯è¤‡é¸ç›¸åŠ ï¼‰
    "diag": {
        "Personality Disorder":    0.35,
        "Substance Use Disorder":  0.35,
        "Bipolar":                 0.10,
        "PTSD":                    0.10,
        "Schizophrenia":           0.10,
        "Depression":              0.05,
        "Anxiety":                 0.00,
        "OCD":                     0.00,
        "Dementia":                0.00,
        "ADHD":                    0.00,
        "Other/Unknown":           0.00,
    },
    # é¡å¤–è¦å‰‡
    "no_followup_extra": 0.20,          # 0 æ¬¡è¿½è¹¤çš„é¡å¤–åŠ ç½°
    # äº¤äº’æ•ˆæ‡‰
    "x_sud_lowcomp": 0.15,              # SUD Ã— complianceâ‰¤3
    "x_pd_shortlos": 0.10,              # PD Ã— LOS<3
}

# ====== Load or train (auto-fallback to demo) ======
def try_load_model(path="dropout_model.pkl"):
    if not os.path.exists(path): return None
    try:
        bundle = joblib.load(path)
        if isinstance(bundle, dict) and "model" in bundle: return bundle["model"]
        return bundle
    except Exception:
        return None

def xgboost_classifier():
    import xgboost as xgb
    return xgb.XGBClassifier(
        n_estimators=450, max_depth=4, learning_rate=0.06,
        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,
        random_state=42, tree_method="hist",
        objective="binary:logistic", eval_metric="logloss",
    )

def train_demo_model(columns):
    import xgboost as xgb
    rng = np.random.default_rng(42)
    n = 9000
    X = pd.DataFrame(0, index=range(n), columns=columns, dtype=np.float32)

    # Marginals
    X["age"] = rng.integers(16, 85, n)
    X["length_of_stay"] = rng.normal(5.0, 3.0, n).clip(0, 45)
    X["num_previous_admissions"] = rng.poisson(0.8, n).clip(0, 12)
    X["medication_compliance_score"] = rng.normal(6.0, 2.5, n).clip(0, 10)
    X["family_support_score"] = rng.normal(5.0, 2.5, n).clip(0, 10)
    X["post_discharge_followups"] = rng.integers(0, 6, n)

    # æ€§åˆ¥ one-hot
    idx_gender = rng.integers(0, len(GENDER_LIST), n)
    for i, g in enumerate(GENDER_LIST):
        X.loc[idx_gender == i, f"gender_{g}"] = 1

    # ä¸»è¨ºæ–· + å¸¸è¦‹å…±ç—…
    idx_primary = rng.integers(0, len(DIAG_LIST), n)
    for i, d in enumerate(DIAG_LIST):
        X.loc[idx_primary == i, f"diagnosis_{d}"] = 1
    extra_probs = {"Substance Use Disorder": 0.20, "Anxiety": 0.20, "Depression": 0.25, "PTSD": 0.10}
    for d, pr in extra_probs.items():
        mask = (rng.random(n) < pr); X.loc[mask, f"diagnosis_{d}"] = 1
    has_any = X[[f"diagnosis_{d}" for d in DIAG_LIST]].sum(axis=1) > 0
    if not has_any.all():
        fix_idx = has_any[~has_any].index
        rp = rng.integers(0, len(DIAG_LIST), len(fix_idx))
        for j, ridx in enumerate(fix_idx):
            X.at[ridx, f"diagnosis_{DIAG_LIST[rp[j]]}"] = 1

    # è‡ªå‚·æ¨™è¨˜
    idx_rsh = rng.integers(0, 2, n)
    idx_shadm = rng.integers(0, 2, n)
    X.loc[idx_rsh == 1, "has_recent_self_harm_Yes"] = 1
    X.loc[idx_rsh == 0, "has_recent_self_harm_No"] = 1
    X.loc[idx_shadm == 1, "self_harm_during_admission_Yes"] = 1
    X.loc[idx_shadm == 0, "self_harm_during_admission_No"] = 1

    # Balanced literature-inspired logitsï¼ˆdemo ç›®æ¨™ï¼‰
    beta0 = -0.60
    beta = {
        "has_recent_self_harm_Yes": 0.80,
        "self_harm_during_admission_Yes": 0.60,
        "prev_adm_ge2": 0.60,
        "medication_compliance_per_point": -0.25,
        "family_support_per_point": -0.20,
        "followups_per_visit": -0.12,
        "length_of_stay_per_day": 0.05,
    }
    beta_diag = {
        "Personality Disorder":    0.35,
        "Substance Use Disorder":  0.35,
        "Bipolar":                 0.10,
        "PTSD":                    0.10,
        "Schizophrenia":           0.10,
        "Depression":              0.05,
        "Anxiety":                 0.00,
        "OCD":                     0.00,
        "Dementia":                0.00,
        "ADHD":                    0.00,
        "Other/Unknown":           0.00,
    }

    prev_ge2 = (X["num_previous_admissions"] >= 2).astype(np.float32)
    logit = (
        beta0
        + beta["has_recent_self_harm_Yes"]        * X["has_recent_self_harm_Yes"]
        + beta["self_harm_during_admission_Yes"]  * X["self_harm_during_admission_Yes"]
        + beta["prev_adm_ge2"]                    * prev_ge2
        + beta["medication_compliance_per_point"] * X["medication_compliance_score"]
        + beta["family_support_per_point"]        * X["family_support_score"]
        + beta["followups_per_visit"]             * X["post_discharge_followups"]
        + beta["length_of_stay_per_day"]          * X["length_of_stay"]
    )
    for d, w in beta_diag.items():
        logit = logit + w * X[f"diagnosis_{d}"]

    noise = rng.normal(0.0, 0.35, n).astype(np.float32)
    p = 1.0 / (1.0 + np.exp(-(logit + noise)))
    y = (rng.random(n) < p).astype(np.int32)

    model = xgboost_classifier()
    model.fit(X, y)   # ç”¨ DataFrame ä¿ç•™ feature_names
    return model

def get_feat_names(m):
    try:
        b = m.get_booster()
        if getattr(b, "feature_names", None): return list(b.feature_names)
    except Exception:
        pass
    if hasattr(m, "feature_names_in_"): return list(m.feature_names_in_)
    return None

model = try_load_model()
loaded = model is not None
use_demo = False
if model is not None:
    names = get_feat_names(model)
    if (names is None) or (abs(len(names) - len(TEMPLATE_COLUMNS)) > 3):
        use_demo = True

if (not loaded) or use_demo:
    model = train_demo_model(TEMPLATE_COLUMNS)
    model_source = "demo (balanced weights, multi-diagnoses, higher baseline)"
else:
    model_source = "loaded from dropout_model.pkl"

# ====== Alignment helpers ======
def get_model_feature_order(m):
    order = None; exp_len = None
    try:
        booster = getattr(m, "get_booster", lambda: None)()
        if booster is not None:
            names = getattr(booster, "feature_names", None)
            if names: order, exp_len = list(names), len(names)
    except Exception:
        pass
    if order is None:
        if hasattr(m, "feature_names_in_"):
            order = list(m.feature_names_in_); exp_len = len(order)
        elif hasattr(m, "n_features_in_"):
            exp_len = int(m.n_features_in_)
    return order, exp_len

def align_df_to_model(df: pd.DataFrame, m):
    names, exp_len = get_model_feature_order(m)
    if names:
        aligned = pd.DataFrame(0, index=df.index, columns=names, dtype=np.float32)
        inter = [c for c in names if c in df.columns]
        aligned.loc[:, inter] = df[inter].astype(np.float32).values
        return aligned, names
    out = df.astype(np.float32)
    if (exp_len is not None) and (out.shape[1] != exp_len):
        if out.shape[1] > exp_len: out = out.iloc[:, :exp_len]
        else:
            add = exp_len - out.shape[1]
            pad = pd.DataFrame(0, index=out.index, columns=[f"_pad_{i}" for i in range(add)], dtype=np.float32)
            out = pd.concat([out, pad], axis=1)
    return out, list(out.columns)

def to_float32_np(df: pd.DataFrame): return df.astype(np.float32).values

# ====== Small helpers ======
def set_onehot_by_prefix(df, prefix, value):
    col = f"{prefix}_{value}"
    if col in df.columns: df.at[0, col] = 1

def set_onehot_by_prefix_multi(df, prefix, values):
    for v in values:
        col = f"{prefix}_{v}"
        if col in df.columns: df.at[0, col] = 1

def flag_yes(row, prefix):
    col = f"{prefix}_Yes"; return (col in row.index) and (row[col] == 1)

# ====== Thresholds + soft classification ======
MOD_CUT = 20
HIGH_CUT = 40
def proba_to_percent(p): return float(p) * 100
def proba_to_score(p): return int(round(proba_to_percent(p)))
def classify_soft(score, mod=MOD_CUT, high=HIGH_CUT, band=BORDER_BAND):
    if score >= high + band: return "High"
    if score >= high - band: return "Moderateâ€“High"
    if score >= mod + band:  return "Moderate"
    if score >= mod - band:  return "Lowâ€“Moderate"
    return "Low"

# ====== Sidebar ======
with st.sidebar:
    st.header("Patient Info")
    age = st.slider("Age", 18, 90, 35)
    gender = st.selectbox("Gender", GENDER_LIST)
    diagnoses = st.multiselect("Diagnoses (multi-select)", DIAG_LIST, default=[])
    length_of_stay = st.slider("Length of Stay (days)", 1, 90, 10)
    num_adm = st.slider("Previous Admissions (1y)", 0, 15, 1)
    compliance = st.slider("Medication Compliance Score (0â€“10)", 0.0, 10.0, 5.0)
    recent_self_harm = st.radio("Recent Self-harm", BIN_YESNO, index=1)
    selfharm_adm = st.radio("Self-harm During Admission", BIN_YESNO, index=1)
    support = st.slider("Family Support Score (0â€“10)", 0.0, 10.0, 5.0)
    followups = st.slider("Post-discharge Followups", 0, 10, 2)

    with st.expander("Advanced calibration", expanded=False):
        cal_shift = st.slider("Calibration (log-odds, global)", -1.0, 1.0, CAL_LOGIT_SHIFT, 0.05)
    CAL_LOGIT_SHIFT = cal_shift

# ====== Build single-row DF ======
X_final = pd.DataFrame(0, index=[0], columns=TEMPLATE_COLUMNS, dtype=float)
for k, v in {
    "age": age,
    "length_of_stay": float(length_of_stay),
    "num_previous_admissions": int(num_adm),
    "medication_compliance_score": float(compliance),
    "family_support_score": float(support),
    "post_discharge_followups": int(followups),
}.items(): X_final.at[0, k] = v
set_onehot_by_prefix(X_final, "gender", gender)
set_onehot_by_prefix_multi(X_final, "diagnosis", diagnoses)
set_onehot_by_prefix(X_final, "has_recent_self_harm", recent_self_harm)
set_onehot_by_prefix(X_final, "self_harm_during_admission", selfharm_adm)

# ====== Predict (align + overlay + calibration + blending) ======
X_aligned_df, used_names = align_df_to_model(X_final, model)
X_np = to_float32_np(X_aligned_df)
p_model = float(model.predict_proba(X_np, validate_features=False)[:, 1][0])

# ---- Policy overlay on logit spaceï¼ˆæ”¶é›†é©…å‹•å› å­ï¼‰----
drivers = []  # list of (label, contribution)
def add_driver(label, val):
    if val != 0:
        drivers.append((label, float(val)))
    return val

lz = _logit(p_model)

# ä½é™¢å²
lz += add_driver("More previous admissions",
                 POLICY["per_prev_admission"] * min(int(X_final.at[0, "num_previous_admissions"]), 5))

# é †å¾ã€å®¶æ”¯ï¼ˆä»¥ 5 ç‚ºä¸­å¿ƒï¼‰
lz += add_driver("Low medication compliance",
                 POLICY["per_point_low_compliance"] * max(0.0, 5.0 - float(X_final.at[0, "medication_compliance_score"])))
lz += add_driver("Low family support",
                 POLICY["per_point_low_support"] * max(0.0, 5.0 - float(X_final.at[0, "family_support_score"])))

# è¿½è¹¤
lz += add_driver("More post-discharge followups (protective)",
                 POLICY["per_followup"] * float(X_final.at[0, "post_discharge_followups"]))
if float(X_final.at[0, "post_discharge_followups"]) == 0:
    lz += add_driver("No follow-up scheduled", POLICY["no_followup_extra"])

# ä½é™¢æ—¥æ•¸
los = float(X_final.at[0, "length_of_stay"])
if los < 3:
    lz += add_driver("Very short stay (<3d)", POLICY["los_short"])
elif los <= 14:
    lz += add_driver("Typical stay (3â€“14d)", POLICY["los_mid"])
elif los <= 21:
    lz += add_driver("Longish stay (15â€“21d)", POLICY["los_mid_high"])
else:
    lz += add_driver("Very long stay (>21d)", POLICY["los_long"])

# å¹´é½¡ï¼ˆæ¥µç«¯ï¼‰
age_val = float(X_final.at[0, "age"])
if age_val < 21:
    lz += add_driver("Young age (<21)", POLICY["age_young"])
elif age_val >= 75:
    lz += add_driver("Older age (â‰¥75)", POLICY["age_old"])

# è¨ºæ–·ï¼ˆå¯è¤‡é¸ç›¸åŠ ï¼‰
for dx, w in POLICY["diag"].items():
    col = f"diagnosis_{dx}"
    if col in X_final.columns and X_final.at[0, col] == 1:
        lz += add_driver(f"Diagnosis: {dx}", w)

# äº¤äº’æ•ˆæ‡‰ï¼ˆç”¨å–®åˆ— row0 å–å¾—ç´”é‡ï¼Œé¿å… Series å¸ƒæ—æ­§ç¾©ï¼‰
row0 = X_final.iloc[0]
has_sud = bool(row0.get("diagnosis_Substance Use Disorder", 0) == 1)
if has_sud and float(row0["medication_compliance_score"]) <= 3:
    lz += add_driver("SUD Ã— very low compliance", POLICY["x_sud_lowcomp"])
has_pd = bool(row0.get("diagnosis_Personality Disorder", 0) == 1)
if has_pd and los < 3:
    lz += add_driver("PD Ã— very short stay", POLICY["x_pd_shortlos"])

# å…¨åŸŸæ ¡æ­£ â†’ overlay æ©Ÿç‡
lz += CAL_LOGIT_SHIFT
p_overlay = _sigmoid(lz)

# å¹³æ»‘æ··åˆï¼šFinal = (1-BLEND)*Model + BLEND*Overlay
p_policy = (1.0 - BLEND_W) * p_model + BLEND_W * p_overlay

# ---- Soft safety upliftï¼ˆä¸é–æ­»ï¼Œåªæå‡ï¼‰----
soft_reason = None
if flag_yes(X_final.iloc[0], "has_recent_self_harm") or flag_yes(X_final.iloc[0], "self_harm_during_admission"):
    p_final = min(max(p_policy, SOFT_UPLIFT["floor"]) + SOFT_UPLIFT["add"], SOFT_UPLIFT["cap"])
    soft_reason = "self-harm uplift"
else:
    p_final = p_policy

percent_model = proba_to_percent(p_model)
percent = proba_to_percent(p_final)
score = proba_to_score(p_final)
level = classify_soft(score)

# ====== Model diagnostics ======
with st.expander("Model diagnostics", expanded=False):
    st.write(f"**Model source:** {model_source}")
    try:
        booster = model.get_booster()
        fmap = booster.get_fscore()
        imp = (pd.Series(fmap, name="split_count")
               .reindex(get_feat_names(model) or [], fill_value=0)
               .sort_values(ascending=False).head(10))
        st.caption("Top-10 features by split count (proxy for importance):")
        st.dataframe(imp.reset_index(names="feature"))
    except Exception as e:
        st.caption(f"Importance not available: {e}")

# ====== Show result ======
st.subheader("Predicted Dropout Risk (within 3 months)")
c1, c2, c3 = st.columns(3)
with c1: st.metric("Model Probability", f"{percent_model:.1f}%")
with c2: st.metric("Final Probability", f"{percent:.1f}%")
with c3: st.metric("Risk Score (0â€“100)", f"{score}")

if soft_reason:
    st.warning(f"ğŸŸ  Soft safety uplift applied ({soft_reason}).")
else:
    if level == "High":
        st.error("ğŸ”´ High Risk")
    elif level == "Moderateâ€“High":
        st.warning("ğŸŸ  Moderateâ€“High (borderline to High)")
    elif level == "Moderate":
        st.warning("ğŸŸ¡ Moderate Risk")
    elif level == "Lowâ€“Moderate":
        st.info("ğŸ”µ Lowâ€“Moderate (borderline to Moderate)")
    else:
        st.success("ğŸŸ¢ Low Risk")

# ====== Why did the risk go up? (policy drivers) ======
with st.expander("Why did the risk go up? (policy drivers)", expanded=False):
    if drivers:
        df_drv = pd.DataFrame(
            [{"driver": k, "log-odds +": round(v, 3)} for k, v in sorted(drivers, key=lambda x: abs(x[1]), reverse=True)]
        )
        st.dataframe(df_drv, use_container_width=True)
    else:
        st.caption("No positive policy drivers; Final is close to the model output and protective factors.")

# ====== SHAP (model-only explanation) ======
with st.expander("SHAP Explanation (model component)", expanded=True):
    st.caption("Positive bars push toward higher dropout risk; negative bars lower it. Only the selected category for each one-hot feature is shown.")
    import xgboost as xgb
    try:
        booster = model.get_booster()
        dmat = xgb.DMatrix(X_aligned_df, feature_names=list(X_aligned_df.columns))
        contribs = booster.predict(dmat, pred_contribs=True, validate_features=False)
        contrib = np.asarray(contribs)[0]
        base_value = float(contrib[-1])
        feat_contrib = contrib[:-1]
        sv_map = dict(zip(list(X_aligned_df.columns), feat_contrib))
    except Exception:
        explainer = shap.TreeExplainer(model)
        sv_raw = explainer.shap_values(X_aligned_df)
        base_value = explainer.expected_value
        if isinstance(base_value, (list, np.ndarray)) and not np.isscalar(base_value):
            base_value = base_value[0]
            if isinstance(sv_raw, list): sv_raw = sv_raw[0]
        sv_raw = sv_raw[0]; sv_map = dict(zip(list(X_aligned_df.columns), sv_raw))

    names, vals, data_vals = [], [], []
    cont_feats = [
        ("Age","age", X_final.at[0,"age"]),
        ("Length of Stay (days)","length_of_stay", X_final.at[0,"length_of_stay"]),
        ("Previous Admissions (1y)","num_previous_admissions", X_final.at[0,"num_previous_admissions"]),
        ("Medication Compliance (0â€“10)","medication_compliance_score", X_final.at[0,"medication_compliance_score"]),
        ("Family Support (0â€“10)","family_support_score", X_final.at[0,"family_support_score"]),
        ("Post-discharge Followups","post_discharge_followups", X_final.at[0,"post_discharge_followups"]),
    ]
    for label, key, dv in cont_feats:
        if key in sv_map: names.append(label); vals.append(float(sv_map[key])); data_vals.append(dv)

    def add_onehot(title, prefix, value):
        col = f"{prefix}_{value}"
        if col in sv_map:
            names.append(f"{title}={value}"); vals.append(float(sv_map[col])); data_vals.append(1)

    for dx in diagnoses: add_onehot("Diagnosis","diagnosis", dx)
    add_onehot("Gender","gender", gender)
    add_onehot("Recent Self-harm","has_recent_self_harm", recent_self_harm)
    add_onehot("Self-harm During Admission","self_harm_during_admission", selfharm_adm)

    if len(vals) == 0:
        st.caption("No SHAP contributions available.")
    else:
        order = np.argsort(np.abs(np.array(vals)))[::-1][:12]
        exp = shap.Explanation(
            values=np.array(vals, dtype=float)[order],
            base_values=base_value,
            feature_names=[names[i] for i in order],
            data=np.array(data_vals, dtype=float)[order],
        )
        shap.plots.waterfall(exp, show=False, max_display=12)
        st.pyplot(plt.gcf(), clear_figure=True)

# ====== Recommended Actions (detailed + Why) ======
st.subheader("Recommended Actions")

# ---- åŸºç·šè™•ç½®ï¼ˆä¾ç­‰ç´šï¼‰----
BASE_ACTIONS = {
    "High": [
        ("Today", "Clinician", "Crisis/safety planning with patient + caregiver; provide 24/7 crisis contacts",
         "High risk requires immediate safety planning"),
        ("Today", "Clinic scheduler", "Book return visit within 7 days (prefer 72h if feasible)",
         "Early follow-up reduces dropout"),
        ("Today", "Care coordinator", "Warm handoff to case management / care navigation",
         "Intensive coordination improves retention"),
        ("48h", "Nurse", "Outreach call to assess symptoms, side-effects, and barriers (document and escalate if needed)",
         "Early outreach lowers early attrition"),
        ("7d", "Pharmacist/Nurse", "Medication review + adherence plan (simplify regimen, pillbox/blister pack, reminders)",
         "Targeted adherence support"),
        ("1â€“2w", "Social worker", "SDOH screen + arrange transport/financial aid if needed",
         "Address practical barriers"),
        ("1â€“4w", "Peer support", "Enroll in peer-support or skills group if available",
         "Engagement booster"),
    ],
    "Moderate": [
        ("1â€“2w", "Clinic scheduler", "Schedule return within 14 days; enroll in SMS/phone reminders",
         "Timely follow-up & reminders"),
        ("1â€“2w", "Nurse", "Barrier check: transport, costs, side-effects; provide solutions",
         "Remove dropout drivers"),
        ("2â€“4w", "Clinician", "Brief MI/BA/psychoeducation; set a concrete plan for next 4 weeks",
         "Improve motivation & structure"),
    ],
    "Low": [
        ("2â€“4w", "Clinic scheduler", "Routine follow-up; confirm contact and reminder preferences",
         "Maintain engagement"),
        ("2â€“4w", "Nurse", "Provide education materials + self-management resources",
         "Support autonomy"),
    ],
}

# æ­£è¦åŒ–å·¥å…·ï¼ˆæŠŠ 3 æ¬„æˆ– 4 æ¬„ tuple çµ±ä¸€æˆ 4 æ¬„ï¼‰
def _normalize_action_tuple(a):
    if len(a) == 4:
        return a
    elif len(a) == 3:
        tl, ow, ac = a
        return (tl, ow, ac, "")
    else:
        return None

def add(actions, tl, owner, act, why):
    actions.append((tl, owner, act, why))

def personalized_actions(row: pd.Series, chosen_dx: list, final_level: str, drivers_list: list):
    acts = []
    age_v   = float(row["age"])
    los_v   = float(row["length_of_stay"])
    adm_v   = float(row["num_previous_admissions"])
    comp_v  = float(row["medication_compliance_score"])
    sup_v   = float(row["family_support_score"])
    fup_v   = float(row["post_discharge_followups"])

    has_selfharm = flag_yes(row, "has_recent_self_harm") or flag_yes(row, "self_harm_during_admission")
    has_sud = ("Substance Use Disorder" in chosen_dx)
    has_pd  = ("Personality Disorder" in chosen_dx)
    has_dep = ("Depression" in chosen_dx)
    has_scz = ("Schizophrenia" in chosen_dx)

    # 1) è‡ªå‚·ç›¸é—œ
    if has_selfharm:
        add(acts, "Today", "Clinician", "C-SSRS / suicide risk assessment; update safety plan; lethal-means counseling",
            "Self-harm flagged")
        add(acts, "Today", "Clinician", "Provide crisis card (hotline/text/ER) and review warning signs",
            "Self-harm flagged")
        add(acts, "48h", "Nurse", "Check-in call on safety plan adherence + symptom changes",
            "Post-discharge safety follow-up")

    # 2) SUD Ã— ä½é †å¾ï¼ˆäº¤äº’ï¼‰
    if has_sud and comp_v <= 3:
        add(acts, "1â€“7d", "Clinician", "Brief motivational interviewing (MI) focused on use goals and treatment plan",
            "SUD with very low adherence")
        add(acts, "1â€“7d", "Care coordinator", "Refer to SUD program / IOP or contingency management (if available)",
            "Higher dropout risk in SUD")
        add(acts, "Today", "Clinician", "Overdose prevention education; provide local resources",
            "Risk reduction for SUD")

    # 3) PD Ã— çŸ­ä½é™¢ï¼ˆäº¤äº’ï¼‰
    if has_pd and los_v < 3:
        add(acts, "Today", "Care coordinator", "Same-day scheduling of DBT/skills group intake",
            "PD with very short stay")
        add(acts, "48h", "Peer support", "Proactive outreach with coping skills workbook",
            "Reinforce engagement early")

    # 4) é †å¾å¾ˆä½
    if comp_v <= 3:
        add(acts, "7d", "Pharmacist", "Medication simplification + adherence aids (pillbox/blister; reminder setup)",
            "Very low adherence")
        add(acts, "1â€“2w", "Clinician", "Discuss treatment options; consider long-acting formulations where appropriate",
            "Stabilize adherence")

    # 5) å®¶åº­æ”¯æŒå¾ˆä½
    if sup_v <= 2:
        add(acts, "1â€“2w", "Clinician", "Family meeting / caregiver engagement (invite to visit; align on plan)",
            "Low family support")
        add(acts, "1â€“2w", "Social worker", "Connect to community supports / benefits; transport and financial counseling",
            "Practical & social supports")

    # 6) è¿½è¹¤ç‚º 0
    if fup_v == 0:
        add(acts, "Today", "Clinic scheduler", "Book 2 touchpoints in first 14 days (e.g., day 2 & day 7 calls/visits)",
            "No follow-up scheduled")

    # 7) ä½é™¢å²å¤š
    if adm_v >= 3:
        add(acts, "1â€“2w", "Care coordinator", "Enroll in case management with weekly check-ins for first month",
            "Multiple prior admissions")

    # 8) ä½é™¢æ—¥æ•¸æ¥µç«¯
    if los_v < 3:
        add(acts, "48h", "Nurse", "Early post-discharge call; review meds and barriers",
            "Very short stay")
    elif los_v > 21:
        add(acts, "1â€“7d", "Care coordinator", "Step-down plan (day program / community bridge) and warm handoff",
            "Very long stay")

    # 9) å¹´é½¡æ¥µç«¯
    if age_v < 21:
        add(acts, "1â€“2w", "Clinician", "Involve guardians; link to school/university counseling if relevant",
            "Young age")
    elif age_v >= 75:
        add(acts, "1â€“2w", "Nurse/Pharmacist", "Medication reconciliation; simplify dosing; assess cognitive/functional needs",
            "Older age")

    # 10) è¨ºæ–·å°å‘ï¼ˆæº«å’Œï¼‰
    if has_dep:
        add(acts, "1â€“2w", "Clinician", "Behavioral activation plan + specific activity schedule",
            "Depressionâ€”activation improves adherence")
    if has_scz:
        add(acts, "1â€“4w", "Clinician", "Psychoeducation on early warning signs & relapse plan; consider caregiver involvement",
            "Schizophreniaâ€”relapse planning helps continuity")

    return acts

# ---- çµ„è£è™•ç½®ï¼ˆåŸºç·š + å€‹äººåŒ–ï¼‰----
base_bucket = {
    "High": "High",
    "Moderateâ€“High": "High",   # é‚Šå¸¶ â†’ ç”¨ä¸Šä¸€ç´šåŸºç·š
    "Moderate": "Moderate",
    "Lowâ€“Moderate": "Low",     # é‚Šå¸¶ â†’ ç”¨ä¸‹ä¸€ç´šåŸºç·š
    "Low": "Low",
}

# åŸºç·šè™•ç½®
_base_list = BASE_ACTIONS[base_bucket[level]]
actions = []
for a in _base_list:
    na = _normalize_action_tuple(a)
    if na is not None:
        actions.append(na)

# å€‹äººåŒ–è™•ç½®
pers = personalized_actions(X_final.iloc[0], diagnoses, level, drivers)
for a in pers:
    na = _normalize_action_tuple(a)
    if na is not None:
        actions.append(na)

# å»é‡ï¼ˆåŒæ¨£çš„ä¸‰æ¬„å‹•ä½œè¦–ç‚ºé‡è¤‡ï¼‰
seen = set(); uniq = []
for tl, ow, ac, why in actions:
    key = (tl, ow, ac)
    if key not in seen:
        seen.add(key)
        uniq.append((tl, ow, ac, why))

# ä¾æ™‚é–“çª—æ’åº
ORDER = {"Today": 0, "48h": 1, "7d": 2, "1â€“7d": 2, "1â€“2w": 3, "2â€“4w": 4, "1â€“4w": 5}
uniq.sort(key=lambda x: (ORDER.get(x[0], 99), x[1], x[2]))

# é¡¯ç¤ºç‚ºè¡¨æ ¼
df_plan = pd.DataFrame(uniq, columns=["Timeline", "Owner", "Action", "Why"])
st.dataframe(df_plan, use_container_width=True)

# ====== SOP exportï¼ˆåŒ…å« Whyï¼›High/Moderateâ€“Highï¼‰======
if level in ["High", "Moderateâ€“High"]:
    def make_sop_txt(score: int, label: str, actions: list) -> BytesIO:
        lines = [
            "Psychiatric Dropout Risk â€“ SOP",
            f"Risk score: {score}/100 | Risk level: {label}",
            ""
        ]
        for (tl, ow, ac, why) in actions:
            why_str = f" (Why: {why})" if why else ""
            lines.append(f"- {tl} | {ow} | {ac}{why_str}")
        buf = BytesIO("\n".join(lines).encode("utf-8")); buf.seek(0); return buf

    st.download_button("â¬‡ï¸ Export SOP (TXT)", make_sop_txt(score, level, uniq),
                       file_name="dropout_risk_SOP.txt", mime="text/plain")

    if HAS_DOCX:
        def make_sop_docx(score: int, label: str, actions: list) -> BytesIO:
            doc = Document()
            doc.add_heading('Psychiatric Dropout Risk â€“ SOP', level=1)
            doc.add_paragraph(f"Risk score: {score}/100 | Risk level: {label}")
            t = doc.add_table(rows=1, cols=4)
            hdr = t.rows[0].cells
            hdr[0].text = 'Timeline'; hdr[1].text = 'Owner'; hdr[2].text = 'Action'; hdr[3].text = 'Why'
            for (tl, ow, ac, why) in actions:
                r = t.add_row().cells
                r[0].text = tl; r[1].text = ow; r[2].text = ac; r[3].text = why or ""
            buf = BytesIO(); doc.save(buf); buf.seek(0); return buf

        st.download_button("â¬‡ï¸ Export SOP (Word)", make_sop_docx(score, level, uniq),
                           file_name="dropout_risk_SOP.docx",
                           mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

# ====== ï¼ˆé ‚å±¤ï¼‰Batch ç”¨çš„å·¥å…·å‡½å¼ï¼šTop-3 æ¨è–¦è™•ç½® ======
def chosen_dx_for_row(i, df_feat):
    """å›å‚³ç¬¬ i åˆ—ç—…äººçš„å¤šé‡è¨ºæ–·æ¸…å–®ï¼ˆä¾ä¸€ç†±ç·¨ç¢¼æ¬„ï¼‰"""
    return [d for d in DIAG_LIST if f"diagnosis_{d}" in df_feat.columns and df_feat.at[i, f"diagnosis_{d}"] == 1]

def top3_actions_for_row(i, out_df, features_df):
    """ä¾é¢¨éšªç­‰ç´š + å€‹äººåŒ–è¦å‰‡ï¼Œç”¢ç”Ÿ Top-3 æ¨è–¦è™•ç½®ï¼ˆå« Whyï¼‰å­—ä¸²"""
    level_i = out_df.loc[i, "risk_level"]
    base_bucket_map = {"High":"High","Moderateâ€“High":"High","Moderate":"Moderate","Lowâ€“Moderate":"Low","Low":"Low"}
    base_lvl = base_bucket_map.get(level_i, "Low")

    # åŸºç·šè™•ç½®ï¼ˆè£œé½Š Why ç©ºå­—ä¸²ï¼‰
    acts = []
    for a in BASE_ACTIONS[base_lvl]:
        na = _normalize_action_tuple(a)
        if na is not None:
            acts.append(na)

    # å€‹äººåŒ–è™•ç½®
    row_series = features_df.iloc[i]
    chosen_dx = chosen_dx_for_row(i, features_df)
    pers = personalized_actions(row_series, chosen_dx, level_i, [])
    for a in pers:
        na = _normalize_action_tuple(a)
        if na is not None:
            acts.append(na)

    # å»é‡ + ä¾æ™‚é–“çª—æ’åº
    seen = set(); uniq = []
    for a in acts:
        tl, ow, ac, why = a
        key = (tl, ow, ac)
        if key not in seen:
            seen.add(key); uniq.append((tl, ow, ac, why))
    ORDER = {"Today": 0, "48h": 1, "7d": 2, "1â€“7d": 2, "1â€“2w": 3, "2â€“4w": 4, "1â€“4w": 5}
    uniq.sort(key=lambda x: (ORDER.get(x[0], 99), x[1], x[2]))

    top = [f"{tl} | {ow} | {ac}" + (f" (Why: {why})" if why else "") for (tl, ow, ac, why) in uniq[:3]]
    return " || ".join(top)

# ====== Batch Prediction (Excel) ======
st.markdown("---")
st.subheader("Batch Prediction (Excel)")

friendly_cols = [
    "Age","Gender","Diagnoses",  # å¤šè¨ºæ–·ï¼ˆé€—è™Ÿ/åˆ†è™Ÿ/æ–œç·š/| åˆ†éš”ï¼‰ï¼Œç›¸å®¹èˆŠæ¬„ä½ Diagnosis
    "Length of Stay (days)","Previous Admissions (1y)",
    "Medication Compliance Score (0â€“10)",
    "Recent Self-harm","Self-harm During Admission",
    "Family Support Score (0â€“10)","Post-discharge Followups"
]
tpl_df = pd.DataFrame(columns=friendly_cols)
tpl_buf = BytesIO(); tpl_df.to_excel(tpl_buf, index=False); tpl_buf.seek(0)
st.download_button("ğŸ“¥ Download Excel Template", tpl_buf, file_name="batch_template.xlsx",
                   mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

uploaded = st.file_uploader("ğŸ“‚ Upload Excel", type=["xlsx"])
if uploaded is not None:
    try:
        raw = pd.read_excel(uploaded)
        df = pd.DataFrame(0, index=raw.index, columns=TEMPLATE_COLUMNS, dtype=float)

        def safe_get(col, default=0): return raw[col] if col in raw.columns else default
        df["age"] = safe_get("Age")
        df["length_of_stay"] = safe_get("Length of Stay (days)")
        df["num_previous_admissions"] = safe_get("Previous Admissions (1y)")
        df["medication_compliance_score"] = safe_get("Medication Compliance Score (0â€“10)")
        df["family_support_score"] = safe_get("Family Support Score (0â€“10)")
        df["post_discharge_followups"] = safe_get("Post-discharge Followups")

        def apply_onehot_prefix_multi(human_col, prefix, options):
            if human_col not in raw.columns: return
            for i, cell in raw[human_col].astype(str).fillna("").items():
                parts = [p.strip() for p in re.split(r"[;,/|]", cell) if p.strip()]
                if not parts and cell.strip(): parts = [cell.strip()]
                for v in parts:
                    if v in options:
                        col = f"{prefix}_{v}"
                        if col in df.columns: df.at[i, col] = 1

        def apply_onehot_prefix(human_col, prefix, options):
            if human_col not in raw.columns: return
            for i, v in raw[human_col].astype(str).str.strip().items():
                if v in options:
                    col = f"{prefix}_{v}"
                    if col in df.columns: df.at[i, col] = 1

        apply_onehot_prefix("Gender","gender", GENDER_LIST)
        if "Diagnoses" in raw.columns:
            apply_onehot_prefix_multi("Diagnoses","diagnosis", DIAG_LIST)
        elif "Diagnosis" in raw.columns:
            apply_onehot_prefix_multi("Diagnosis","diagnosis", DIAG_LIST)
        apply_onehot_prefix("Recent Self-harm","has_recent_self_harm", BIN_YESNO)
        apply_onehot_prefix("Self-harm During Admission","self_harm_during_admission", BIN_YESNO)

        Xb_aligned, _ = align_df_to_model(df, model)
        Xb_np = to_float32_np(Xb_aligned)
        base_probs = model.predict_proba(Xb_np, validate_features=False)[:, 1]

        # ---- Vectorized policy overlay for batchï¼ˆå«å¹´é½¡ã€é›¶è¿½è¹¤åŠ ç½°ã€äº¤äº’æ•ˆæ‡‰ï¼‰----
        lz = _logit_vec(base_probs)

        # ä½é™¢å²
        lz += POLICY["per_prev_admission"] * np.minimum(df["num_previous_admissions"].astype(float).to_numpy(), 5)

        # é †å¾ã€å®¶æ”¯
        lz += POLICY["per_point_low_compliance"] * np.maximum(0.0, 5.0 - df["medication_compliance_score"].astype(float).to_numpy())
        lz += POLICY["per_point_low_support"] * np.maximum(0.0, 5.0 - df["family_support_score"].astype(float).to_numpy())

        # è¿½è¹¤ + é›¶è¿½è¹¤åŠ ç½°
        fup = df["post_discharge_followups"].astype(float).to_numpy()
        lz += POLICY["per_followup"] * fup
        lz += POLICY["no_followup_extra"] * (fup == 0)

        # LOS
        los_arr = df["length_of_stay"].astype(float).to_numpy()
        lz += np.where(los_arr < 3, POLICY["los_short"],
                np.where(los_arr <= 14, POLICY["los_mid"],
                np.where(los_arr <= 21, POLICY["los_mid_high"], POLICY["los_long"])))

        # å¹´é½¡æ¥µç«¯
        age_arr = df["age"].astype(float).to_numpy()
        lz += POLICY["age_young"] * (age_arr < 21)
        lz += POLICY["age_old"]   * (age_arr >= 75)

        # è¨ºæ–·
        diag_term = np.zeros(len(df), dtype=float)
        for dx, w in POLICY["diag"].items():
            col = f"diagnosis_{dx}"
            if col in df.columns:
                diag_term += w * (df[col].to_numpy() == 1)
        lz += diag_term

        # äº¤äº’æ•ˆæ‡‰
        sud = (df.get("diagnosis_Substance Use Disorder", 0).to_numpy() == 1)
        very_low_comp = (df["medication_compliance_score"].astype(float).to_numpy() <= 3)
        lz += POLICY["x_sud_lowcomp"] * (sud & very_low_comp)

        pd_mask = (df.get("diagnosis_Personality Disorder", 0).to_numpy() == 1)
        lz += POLICY["x_pd_shortlos"] * (pd_mask & (los_arr < 3))

        # æ ¡æ­£ + æ··åˆ
        lz += CAL_LOGIT_SHIFT
        p_overlay = 1.0 / (1.0 + np.exp(-lz))
        p_policy = (1.0 - BLEND_W) * base_probs + BLEND_W * p_overlay

        # self-harm uplift
        hrsh = df.get("has_recent_self_harm_Yes", 0)
        shadm = df.get("self_harm_during_admission_Yes", 0)
        soft_mask = ((np.array(hrsh) == 1) | (np.array(shadm) == 1))
        adj_probs = p_policy.copy()
        adj_probs[soft_mask] = np.minimum(
            np.maximum(adj_probs[soft_mask], SOFT_UPLIFT["floor"]) + SOFT_UPLIFT["add"],
            SOFT_UPLIFT["cap"]
        )

        out = raw.copy()
        out["risk_percent"] = (adj_probs * 100).round(1)
        out["risk_score_0_100"] = (adj_probs * 100).round().astype(int)

        # é‚Šå¸¶åˆ†ç´šï¼ˆå‘é‡åŒ–ï¼‰
        s = out["risk_score_0_100"].to_numpy()
        levels = np.full(s.shape, "Low", dtype=object)
        levels[s >= MOD_CUT - BORDER_BAND] = "Lowâ€“Moderate"
        levels[s >= MOD_CUT + BORDER_BAND] = "Moderate"
        levels[s >= HIGH_CUT - BORDER_BAND] = "Moderateâ€“High"
        levels[s >= HIGH_CUT + BORDER_BAND] = "High"
        out["risk_level"] = levels

        # policy drivers top3ï¼ˆç°¡åŒ–é‡ç¾ä¸»è¦é …ï¼‰
        top3_list = []
        for i in range(len(df)):
            contribs = []
            def push(name, val):
                if val != 0: contribs.append((name, float(val)))
            # ä½é™¢å²
            push("More previous admissions", POLICY["per_prev_admission"] * min(float(df.iloc[i]["num_previous_admissions"]), 5))
            # é †å¾/å®¶æ”¯
            push("Low medication compliance", POLICY["per_point_low_compliance"] * max(0.0, 5.0 - float(df.iloc[i]["medication_compliance_score"])))
            push("Low family support", POLICY["per_point_low_support"] * max(0.0, 5.0 - float(df.iloc[i]["family_support_score"])))
            # è¿½è¹¤
            fu_i = float(df.iloc[i]["post_discharge_followups"])
            push("More post-discharge followups (protective)", POLICY["per_followup"] * fu_i)
            if fu_i == 0: push("No follow-up scheduled", POLICY["no_followup_extra"])
            # LOS
            los_i = float(df.iloc[i]["length_of_stay"])
            if los_i < 3: push("Very short stay (<3d)", POLICY["los_short"])
            elif los_i <= 14: push("Typical stay (3â€“14d)", POLICY["los_mid"])
            elif los_i <= 21: push("Longish stay (15â€“21d)", POLICY["los_mid_high"])
            else: push("Very long stay (>21d)", POLICY["los_long"])
            # å¹´é½¡
            age_i = float(df.iloc[i]["age"])
            if age_i < 21: push("Young age (<21)", POLICY["age_young"])
            elif age_i >= 75: push("Older age (â‰¥75)", POLICY["age_old"])
            # è¨ºæ–·
            for dx, w in POLICY["diag"].items():
                if f"diagnosis_{dx}" in df.columns and df.iloc[i][f"diagnosis_{dx}"] == 1:
                    push(f"Diagnosis: {dx}", w)
            # äº¤äº’
            sud_i = (df.iloc[i].get("diagnosis_Substance Use Disorder", 0) == 1)
            if sud_i and float(df.iloc[i]["medication_compliance_score"]) <= 3:
                push("SUD Ã— very low compliance", POLICY["x_sud_lowcomp"])
            pd_i = (df.iloc[i].get("diagnosis_Personality Disorder", 0) == 1)
            if pd_i and los_i < 3:
                push("PD Ã— very short stay", POLICY["x_pd_shortlos"])

            if len(contribs) == 0:
                top3_list.append("")
            else:
                contribs.sort(key=lambda x: abs(x[1]), reverse=True)
                top3 = [f"{n} ({v:+.2f})" for n, v in contribs[:3]]
                top3_list.append(" | ".join(top3))
        out["policy_drivers_top3"] = top3_list

        # æ¨è–¦è™•ç½® Top-3
        out["recommended_actions_top3"] = [ top3_actions_for_row(i, out, df) for i in range(len(out)) ]

        st.dataframe(out, use_container_width=True)
        buf_out = BytesIO(); out.to_csv(buf_out, index=False); buf_out.seek(0)
        st.download_button("â¬‡ï¸ Download Results (CSV)", buf_out, "predictions.csv", "text/csv")
    except Exception as e:
        st.error(f"Error: {e}")
